{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"LiveSync","text":"<p>LiveSync is a modular graph-based framework designed for real-time media processing and synchronization. It provides an elegant solution for building complex media processing pipelines while maintaining precise timing and synchronization between different data streams.</p>"},{"location":"#why-livesync","title":"Why LiveSync?","text":"<ul> <li>Graph-Based Architecture: Build complex processing pipelines using a simple, intuitive DAG structure</li> <li>Real-Time Processing: Optimized for handling continuous data streams with minimal latency</li> <li>Flexible Node System: Create custom processing nodes or use pre-built ones for common media operations</li> <li>Async-First Design: Leverages Python's asyncio for efficient concurrent processing</li> </ul>"},{"location":"#get-started","title":"Get Started","text":"<p>New to LiveSync? Follow the Installation Guide to set up your environment and run your first pipeline.</p> <p>For a quick introduction, check out our Quick Start.</p>"},{"location":"#features","title":"Features","text":"<p>\u2714 Real-time media processing \u2714 Automatic stream synchronization \u2714 Modular node system \u2714 Distributed processing via gRPC \u2714 Live streaming capabilities</p>"},{"location":"#documentation-overview","title":"Documentation Overview","text":"<ul> <li>Getting Started \u2013 Install and set up LiveSync.</li> <li>User Guide \u2013 Learn about core concepts like nodes, graphs, and frames.</li> <li>Examples \u2013 Sample pipelines and advanced use cases.</li> </ul>"},{"location":"#get-involved","title":"Get Involved","text":"<p>LiveSync is open-source and actively maintained by OS Designers, Inc.. Join our community, contribute, or report issues on our GitHub repository.</p> <p>\ud83d\udd17 GitHub: os-designers/livesync \ud83d\udcc4 License: MIT</p>"},{"location":"examples/advanced/","title":"Advanced Examples","text":""},{"location":"examples/advanced/#media-processing-pipeline","title":"Media Processing Pipeline","text":""},{"location":"examples/advanced/#video-recording","title":"Video Recording","text":"<pre><code>from livesync import Graph\nfrom livesync.prebuilt.nodes import WebcamNode, FrameRateNode, VideoRecorderNode\n\nworkflow = Graph()\n\n# Configure nodes\nwebcam = WebcamNode(name=\"webcam\", device_id=0, fps=30)\nframe_rate = FrameRateNode(name=\"frame_rate\", fps=15)\nrecorder = VideoRecorderNode(name=\"recorder\", filename=\"output.mp4\", fps=15)\n\n# Build pipeline\nworkflow.add_node(webcam)\nworkflow.add_node(frame_rate)\nworkflow.add_node(recorder)\n\nworkflow.add_edge(webcam, frame_rate)\nworkflow.add_edge(frame_rate, recorder)\n</code></pre>"},{"location":"examples/advanced/#audiovideo-synchronization","title":"Audio/Video Synchronization","text":"<pre><code>from livesync import Graph\nfrom livesync.prebuilt.nodes import WebcamNode, MicrophoneNode, MediaSyncNode\n\nworkflow = Graph()\n\n# Create media sources\nvideo = WebcamNode(name=\"webcam\", fps=30)\naudio = MicrophoneNode(name=\"mic\", sample_rate=44100)\n\n# Configure sync node\nsync = MediaSyncNode(\n    name=\"sync\",\n    buffer_size=30,\n    max_sync_threshold_us=5000,\n    audio_node=\"mic\",\n    video_node=\"webcam\"\n)\n\n# Build pipeline\nworkflow.add_edge(video, sync)\nworkflow.add_edge(audio, sync)\n</code></pre>"},{"location":"examples/advanced/#remote-processing","title":"Remote Processing","text":"<pre><code>from livesync import Graph\nfrom livesync.prebuilt import RemoteNode, WebcamNode\n\nworkflow = Graph()\n\n# Configure nodes\nwebcam = WebcamNode(name=\"webcam\", fps=30)\nremote = RemoteNode(\n    name=\"remote\",\n    endpoints=[\"localhost:50051\"],\n    settings={\"resolution_node\": {\"target_height\": \"320\"}}\n)\n\nworkflow.add_edge(webcam, remote)\n</code></pre>"},{"location":"examples/basic/","title":"Basic Examples","text":""},{"location":"examples/basic/#linear-chain-processing","title":"Linear Chain Processing","text":"<p>LiveSync supports both class-based and functional approaches for creating nodes. Here are two equivalent implementations:</p>"},{"location":"examples/basic/#class-based-approach","title":"Class-based Approach","text":"<pre><code>from livesync import Node, Field, Graph\n\nclass NumberNode(Node):\n    number: int = Field(default=..., description=\"Number to output\")\n\n    def step(self) -&gt; int:\n        return self.number\n\nclass MultiplierNode(Node):\n    source: str = Field(default=..., description=\"Source node name\")\n    factor: int = Field(default=..., description=\"Multiplication factor\")\n\n    async def step(self) -&gt; int:\n        input_value = await self.get_input(self.source)\n        return input_value * self.factor\n\n# Build pipeline\nworkflow = Graph()\nnode_x = NumberNode(number=2)\nnode_y = MultiplierNode(factor=3, source=node_x.name)\n</code></pre>"},{"location":"examples/basic/#functional-approach","title":"Functional Approach","text":"<pre><code>from livesync import Node, Graph\n\n# Define processing functions\ndef return_two(self: Node) -&gt; int:\n    return 2\n\nasync def multiply_by_three(self: Node) -&gt; int:\n    input_value = await self.get_input(\"x\")\n    return input_value * 3\n\n# Build pipeline\nworkflow = Graph()\nnode_x = Node(name=\"x\", step_func=return_two)\nnode_y = Node(name=\"y\", step_func=multiply_by_three)\n</code></pre>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>LiveSync is a graph-based video processing framework designed for real-time applications. This guide will walk you through setting it up on your system.</p>"},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10 or higher</li> <li>pip (latest version recommended)</li> <li>FFmpeg (for video processing)</li> <li>OpenCV (automatically installed with LiveSync)</li> </ul>"},{"location":"getting-started/installation/#installing-livesync","title":"Installing LiveSync","text":""},{"location":"getting-started/installation/#option-1-using-rye-recommended","title":"Option 1: Using <code>rye</code> (Recommended)","text":"<pre><code>rye add livesync-io\n</code></pre>"},{"location":"getting-started/installation/#option-2-using-pip","title":"Option 2: Using <code>pip</code>","text":"<pre><code>pip install livesync-io\n</code></pre>"},{"location":"getting-started/installation/#verifying-installation","title":"Verifying Installation","text":"<p>After installation, verify that LiveSync is installed correctly:</p> <pre><code>python -c \"import livesync; print(livesync.__version__)\"\n</code></pre> <p>If the installation was successful, you should see the LiveSync version number.</p> <p>Next Steps Now that LiveSync is installed, check out the Quick Start Guide to create your first processing pipeline.</p>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>This guide walks you through creating your first LiveSync pipeline for media processing.</p>"},{"location":"getting-started/quickstart/#creating-a-simple-video-pipeline","title":"Creating a Simple Video Pipeline","text":"<p>LiveSync uses a graph-based architecture where nodes represent different processing steps. Let's create a simple video processing pipeline.</p>"},{"location":"getting-started/quickstart/#example-webcam-recording-pipeline","title":"Example: Webcam Recording Pipeline","text":"<pre><code>from livesync import Graph\nfrom livesync.prebuilt.nodes import WebcamNode, FrameRateNode, VideoRecorderNode\nfrom livesync.prebuilt.callbacks import NodeMonitoringCallback\n\n# Create a new graph\nworkflow = Graph()\n\n# Create nodes\nnode_x = WebcamNode(name=\"webcam\", device_id=0, fps=30)    # Capture frames\nnode_y = FrameRateNode(name=\"frame_rate\", fps=10)          # Control frame rate\nnode_z = VideoRecorderNode(filename=\"./output.mp4\", fps=5) # Record video\n\n# Add nodes to graph\nworkflow.add_node(node_x)\nworkflow.add_node(node_y)\nworkflow.add_node(node_z)\n\n# Connect nodes\nworkflow.add_edge(node_x, node_y)\nworkflow.add_edge(node_y, node_z)\n\n# Run the pipeline\nwith workflow.compile() as runner:\n    try:\n        run = runner.run(callback=NodeMonitoringCallback())\n        print(run)\n    except KeyboardInterrupt:\n        print(\"\\nKeyboardInterrupt: Stopping runner.\")\n</code></pre> <p>This pipeline:</p> <ol> <li>Captures video from your webcam at 30 FPS</li> <li>Processes it through a frame rate controller to achieve 10 FPS</li> <li>Records the output to a video file at 10 FPS</li> </ol>"},{"location":"getting-started/quickstart/#running-the-example","title":"Running the Example","text":"<p>Save the script as <code>webcam_recording.py</code> and run:</p> <pre><code>python webcam_recording.py\n</code></pre> <p>The pipeline will start capturing from your webcam and save the processed video to <code>output.mp4</code>.</p>"},{"location":"getting-started/quickstart/#pipeline-visualization","title":"Pipeline Visualization","text":"<pre><code>(Webcam) =&gt; (Frame Rate) =&gt; (Video Recorder)\n   30fps        10fps           10fps\n</code></pre> <p>Next Steps</p> <ul> <li>Learn about more complex pipelines in the User Guide</li> <li>Explore pre-built nodes in the Node Reference</li> <li>See more examples in the Examples section</li> </ul>"},{"location":"user-guide/core-concepts/","title":"Core Concepts","text":"<p>LiveSync is built around a graph-based processing model that enables flexible media processing pipelines. Here are the key concepts you need to understand:</p>"},{"location":"user-guide/core-concepts/#core-components","title":"Core Components","text":""},{"location":"user-guide/core-concepts/#1-graphs","title":"1. Graphs","text":"<p>The main container that manages the processing pipeline:</p> <pre><code>from livesync import Graph\n\ngraph = Graph()\n</code></pre>"},{"location":"user-guide/core-concepts/#2-nodes","title":"2. Nodes","text":"<p>Processing units that can be connected to form a pipeline. Nodes can be created in two ways:</p> <pre><code># Class-based approach\nclass ProcessingNode(Node):\n    def step(self):\n        return 42\n\n# Functional approach\nnode = Node(name=\"processor\", step_func=lambda self: 42)\n</code></pre>"},{"location":"user-guide/core-concepts/#3-frames","title":"3. Frames","text":"<p>Specialized containers for media data:</p> <pre><code>from livesync import VideoFrame, AudioFrame\n\nvideo_frame = VideoFrame(\n    data=frame_data,\n    timestamp_us=1234567,\n    width=1920,\n    height=1080,\n    buffer_type=\"rgb24\"\n)\n</code></pre>"},{"location":"user-guide/core-concepts/#example-pipeline","title":"Example Pipeline","text":"<p>Here's a complete example of a basic processing pipeline:</p> <pre><code>from livesync import Graph, Node\n\n# Create processing pipeline\ngraph = Graph()\n\n# Define nodes\nsource = Node(name=\"source\", step_func=lambda self: 2)\nprocessor = Node(\n    name=\"processor\",\n    step_func=lambda self: self.get_input(\"source\") * 3\n)\n\n# Build graph\ngraph.add_node(source)\ngraph.add_node(processor)\ngraph.add_edge(source, processor)\n\n# Execute\nwith graph.compile() as runner:\n    runner.run(continuous=False)\n</code></pre>"},{"location":"user-guide/core-concepts/#pipeline-execution","title":"Pipeline Execution","text":"<pre><code># Synchronous execution\nwith graph.compile() as runner:\n    runner.run(continuous=True)\n\n# Asynchronous execution\nasync with graph.compile() as runner:\n    run = await runner.async_run()\n    await run.wait()\n</code></pre> <p>Next Steps: Dive deeper into Nodes and Graphs.</p>"},{"location":"user-guide/frames/","title":"Frames","text":"<p>LiveSync provides specialized frame classes for handling different types of media data. The frame system is built around two main classes: <code>AudioFrame</code> and <code>VideoFrame</code>, both inheriting from <code>BaseFrame</code>.</p>"},{"location":"user-guide/frames/#frame-types","title":"Frame Types","text":""},{"location":"user-guide/frames/#audio-frames","title":"Audio Frames","text":"<pre><code>from livesync import AudioFrame\nimport numpy as np\n\n# Create an audio frame\naudio_frame = AudioFrame(\n    data=np.zeros((1024, 2)),          # (samples, channels)\n    timestamp_us=1234567,              # microseconds\n    sample_rate=44100,                 # Hz\n    num_channels=2,                    # 1 (mono) or 2 (stereo)\n    sample_format=\"float32\",           # float32, int16, int32, uint8\n    channel_layout=\"stereo\"            # mono or stereo\n)\n</code></pre>"},{"location":"user-guide/frames/#video-frames","title":"Video Frames","text":"<pre><code>from livesync import VideoFrame\nimport numpy as np\n\n# Create a video frame\nvideo_frame = VideoFrame(\n    data=np.zeros((1080, 1920, 3)),   # (height, width, channels)\n    timestamp_us=1234567,              # microseconds\n    width=1920,\n    height=1080,\n    buffer_type=\"rgb24\"               # rgba, rgb24, i420, etc.\n)\n</code></pre>"},{"location":"user-guide/frames/#supported-formats","title":"Supported Formats","text":""},{"location":"user-guide/frames/#video-buffer-types","title":"Video Buffer Types","text":"<ul> <li>4-channel: <code>rgba</code>, <code>abgr</code>, <code>argb</code>, <code>bgra</code></li> <li>3-channel: <code>rgb24</code></li> <li>YUV formats: <code>i420</code>, <code>i420a</code>, <code>i422</code>, <code>i444</code></li> </ul>"},{"location":"user-guide/frames/#audio-sample-formats","title":"Audio Sample Formats","text":"<ul> <li><code>float32</code></li> <li><code>int16</code></li> <li><code>int32</code></li> <li><code>uint8</code></li> </ul>"},{"location":"user-guide/frames/#serialization","title":"Serialization","text":"<p>Both frame types support serialization for network transmission or storage:</p> <pre><code># Serialize\nframe_bytes = video_frame.tobytes()\n\n# Deserialize\nrestored_frame = VideoFrame.frombytes(frame_bytes)\n</code></pre>"},{"location":"user-guide/frames/#frame-validation","title":"Frame Validation","text":"<p>Frames automatically validate their data on creation:</p> <ul> <li>Correct dimensionality (2D for audio, 3D for video)</li> <li>Valid format types</li> <li>Positive timestamps</li> <li>Matching channel counts</li> <li>Correct buffer types</li> </ul>"},{"location":"user-guide/frames/#example-usage-in-node","title":"Example Usage in Node","text":"<pre><code>from livesync import Node, VideoFrame\nimport numpy as np\n\nclass VideoProcessingNode(Node):\n    async def step(self) -&gt; VideoFrame:\n        # Get input frame\n        input_frame: VideoFrame = await self.get_input(\"camera\")\n\n        # Process frame data\n        processed_data = np.array(input_frame.data) * 1.5\n\n        # Create new frame\n        return VideoFrame(\n            data=processed_data,\n            timestamp_us=input_frame.timestamp_us,\n            width=input_frame.width,\n            height=input_frame.height,\n            buffer_type=input_frame.buffer_type\n        )\n</code></pre> <p>Next Steps: Learn about Pre-built Nodes for media processing.</p>"},{"location":"user-guide/graphs/","title":"Graphs","text":"<p>Graphs in LiveSync represent the processing pipeline structure. They manage node connections and data flow between nodes.</p>"},{"location":"user-guide/graphs/#creating-a-graph","title":"Creating a Graph","text":"<pre><code>from livesync import Graph, Node\n\n# Create a new graph\ngraph = Graph()\n\n# Add nodes and connections\nnode_a = Node(name=\"a\", step_func=lambda self: 42)\nnode_b = Node(name=\"b\", step_func=lambda self: self.get_input(\"a\") * 2)\n\ngraph.add_node(node_a)\ngraph.add_node(node_b)\ngraph.add_edge(node_a, node_b)\n</code></pre>"},{"location":"user-guide/graphs/#running-a-graph","title":"Running a Graph","text":"<p>LiveSync supports both synchronous and asynchronous execution:</p>"},{"location":"user-guide/graphs/#synchronous-execution","title":"Synchronous Execution","text":"<pre><code># Using context manager (recommended)\nwith graph.compile() as runner:\n    runner.run(continuous=False)\n</code></pre>"},{"location":"user-guide/graphs/#asynchronous-execution","title":"Asynchronous Execution","text":"<pre><code>async def main():\n    async with graph.compile() as runner:\n        run = await runner.async_run(continuous=False)\n        await run.wait()\n</code></pre>"},{"location":"user-guide/graphs/#execution-modes","title":"Execution Modes","text":""},{"location":"user-guide/graphs/#one-shot-execution","title":"One-shot Execution","text":"<pre><code>runner.run(continuous=False)  # Run once and stop\n</code></pre>"},{"location":"user-guide/graphs/#continuous-processing","title":"Continuous Processing","text":"<pre><code>runner.run(continuous=True)  # Run continuously until stopped\n</code></pre>"},{"location":"user-guide/graphs/#monitoring-execution","title":"Monitoring Execution","text":"<p>Use callbacks to monitor graph execution:</p> <pre><code>from livesync.prebuilt.callbacks import LoggingCallback\n\nwith graph.compile() as runner:\n    run = runner.run(\n        continuous=True,\n        callback=LoggingCallback()\n    )\n</code></pre>"},{"location":"user-guide/graphs/#example-linear-chain","title":"Example: Linear Chain","text":"<pre><code>from livesync import Graph, Node\n\n# Create a processing chain\nworkflow = Graph()\n\n# Define nodes\nnode_x = Node(name=\"x\", step_func=lambda self: 2)\nnode_y = Node(name=\"y\", step_func=lambda self: self.get_input(\"x\") * 3)\nnode_z = Node(name=\"z\", step_func=lambda self: self.get_input(\"y\") * 2)\n\n# Build graph\nworkflow.add_node(node_x)\nworkflow.add_node(node_y)\nworkflow.add_node(node_z)\n\nworkflow.add_edge(node_x, node_y)\nworkflow.add_edge(node_y, node_z)\n\n# Execute\nwith workflow.compile() as runner:\n    runner.run(continuous=False)\n</code></pre>"},{"location":"user-guide/graphs/#graph-visualization","title":"Graph Visualization","text":"<pre><code>Linear Chain:\n(X) -&gt; (Y) -&gt; (Z)\n\nParallel Processing:\n    -&gt; (B) -&gt;\n(A)         (D)\n    -&gt; (C) -&gt;\n</code></pre> <p>Next Steps: Explore Pre-built Nodes for common processing tasks.</p>"},{"location":"user-guide/nodes/","title":"Nodes","text":"<p>Nodes in LiveSync are flexible processing units that can be created either through inheritance or direct function assignment. This flexibility allows you to choose the most convenient approach for your use case.</p>"},{"location":"user-guide/nodes/#creating-nodes","title":"Creating Nodes","text":""},{"location":"user-guide/nodes/#1-class-based-approach","title":"1. Class-based Approach","text":"<p>Inherit from <code>Node</code> and define lifecycle methods:</p> <pre><code>from livesync import Node, Field\n\nclass NumberNode(Node):\n    number: int = Field(default=..., description=\"Number to output\")\n\n    async def bootstrap(self):\n        \"\"\"Optional initialization\"\"\"\n        print(\"Starting up...\")\n\n    def step(self) -&gt; int:\n        \"\"\"Main processing logic\"\"\"\n        return self.number\n\n    async def shutdown(self):\n        \"\"\"Optional cleanup\"\"\"\n        print(\"Shutting down...\")\n</code></pre>"},{"location":"user-guide/nodes/#2-functional-approach","title":"2. Functional Approach","text":"<p>Directly assign processing functions to <code>Node</code>:</p> <pre><code>from livesync import Node\n\n# Sync function\ndef process_data(self: Node):\n    return 42\n\n# Async function\nasync def process_data_async(self: Node):\n    input_value = await self.get_input(\"source\")\n    return input_value * 2\n\nnode_a = Node(name=\"sync_node\", step_func=process_data)\nnode_b = Node(name=\"async_node\", step_func=process_data_async)\n</code></pre>"},{"location":"user-guide/nodes/#node-lifecycle-methods","title":"Node Lifecycle Methods","text":"<p>Nodes support three optional lifecycle methods:</p> <ol> <li>bootstrap: Initialization (sync/async)</li> <li>step: Main processing (sync/async/generator/async generator)</li> <li>shutdown: Cleanup (sync/async)</li> </ol>"},{"location":"user-guide/nodes/#inputoutput-handling","title":"Input/Output Handling","text":"<p>Nodes can receive inputs from parent nodes and send outputs to child nodes:</p> <pre><code>async def process(self: Node):\n    # Get input from a specific parent\n    data = await self.get_input(\"parent_name\")\n\n    # Get all inputs as a dictionary\n    inputs = await self.get_inputs()\n\n    # Process and return (automatically sent to children)\n    return processed_data\n</code></pre>"},{"location":"user-guide/nodes/#example-complete-pipeline","title":"Example: Complete Pipeline","text":"<pre><code>from livesync import Graph, Node\n\n# Create nodes\nnode_x = Node(name=\"x\", step_func=lambda self: 2)\nnode_y = Node(name=\"y\", step_func=lambda self: self.get_input(\"x\") * 3)\n\n# Build pipeline\ngraph = Graph()\ngraph.add_node(node_x)\ngraph.add_node(node_y)\ngraph.add_edge(node_x, node_y)\n\n# Execute\nwith graph.compile() as runner:\n    runner.run(continuous=False)\n</code></pre> <p>Next Steps: Learn about Graphs to understand pipeline construction.</p>"}]}